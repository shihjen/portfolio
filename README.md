# Projects

<!-- ![banner](/assets/img/profile_banner.jpg) -->

## Kidney Failure Risk Prediction in Intensive Care Unit (ICU) Patients

<td>
  <a href=' '><img src="https://img.shields.io/badge/Machine Learning-green" alt="Machine Learning Badge"></a>
</td>

In this individual project for the course SPH6004 Advanced Statistical Learning, I developed a strategy to select the optimal combination of features for predicting the risk of kidney failure in ICU patients using real-world Electronic Medical Record (EMR) data from the MIMIC-IV database. The process involved inspecting the dataset for duplicate records and missing values, followed by data preprocessing steps such as encoding, scaling, and imputation. I trained predictive models using various machine learning algorithms, including tree-based methods and boosting algorithms. To achieve optimal model performance, I applied several feature selection techniques, including filter methods, embedded methods, and wrapper methods like recursive feature elimination, stepwise feature selection, and genetic algorithms. 11 models were trained using various feature subsets with different learning algorithms. With the project's goal being the construction of a model capable of accurately estimating the likelihood of ICU patients developing AKI, a preference was given to models exhibiting high average precision. Notably, all models demonstrated comparable AUC (ranging from 0.694 to 0.739) and average precision scores (ranging from 0.801 to 0.847).

<a href="https://github.com/shihjen/AKI_Prediction_ICU_Patients" class="button-link">View Project</a>

![icu](/assets/img/icu.jpg)

## Oligomer Order & Usage Tracker System

<td>
  <a href=''><img src="https://img.shields.io/badge/Streamlit-red" alt="Streamlit Badge"></a>
  <a href=''><img src="https://img.shields.io/badge/Dashboard-lightblue" alt="Dahsboard Badge"></a>
</td>

This is web application using Python programming to automate the process of tracking usage and order records of oligomers in Assistant Professor Chris Sham Lok-To's laboratory. The application extracts data from invoices and uploads it to a Google spreadsheet for record keeping. It includes a usage dashboard to display expenses and usage breakdowns, as well as document details such as purchase order numbers, sales order numbers, invoice numbers, and delivery orders. By simply uploading invoices, all information is collected automatically, eliminating the need for manual data entry. This significantly helps reduce repetitive tasks and minimize errors.

<a href="https://github.com/shihjen/oligomer_usage_tracker_system/tree/main" class="button-link">View Project</a>

![oligomer](/assets/img/workflow.jpg)

## YouTube Summarizer

<td>
  <a href=' '><img src="https://img.shields.io/badge/Streamlit-red" alt="Streamlit Badge"></a>
  <a href=' '><img src="https://img.shields.io/badge/Large Language Model-purple" alt="Large Language Model Badge"></a> 
</td>

Video content has become a dominant medium for information dissemination and entertainment. YouTube, as one of the largest video-sharing platforms, hosts an immense variety of content ranging from educational lectures, news, and tutorials to entertainment. However, the sheer volume of content can be overwhelming for users who may not have the time to watch lengthy videos. A solution to this problem is a web application that leverages the capabilities of large language models (LLMs) to generate concise summaries of YouTube video transcripts. This application aims to provide users with quick, comprehensive overviews of video content, saving them time and enhancing their content consumption experience.

<a href="https://github.com/shihjen/YouTube_Summarizer" class="button-link">View Project</a>

![youtube](/assets/img/yt_summarizer.png)


## YouTube Sentiment Analyzer

<td>
  <a href=' '><img src="https://img.shields.io/badge/Streamlit-red" alt="Streamlit Badge"></a>
  <a href=' '><img src="https://img.shields.io/badge/TextBlob-blue" alt="TextBlob Badge"></a> 
</td>

The YouTube Sentiment Analyzer is a web application designed to provide detailed sentiment analysis of YouTube video comments. By leveraging the YouTube Data API and the TextBlob library, this tool allows users to:

- Extract Comments: Gather comments from any YouTube video by simply entering the video URL.
- Analyze Sentiment: Categorize comments into positive, negative, or neutral sentiments based on computed polarity scores.
- Visualize Data: Generate insightful visualizations including wordcloud, sentiment distributions, and polarity histograms.

<a href="https://shihjen-youtube-sentimentanalyzer-app-7ecszs.streamlit.app/" class="button-link">Web Application</a>

![youtube](/assets/img/youtube.jpg)

## PDF Summarizer

<td>
  <a href=' '><img src="https://img.shields.io/badge/Streamlit-red" alt="Streamlit Badge"></a>
  <a href=' '><img src="https://img.shields.io/badge/Large Language Model-purple" alt="Large Language Model Badge"></a> 
</td>

Text Summarization is a natural language processing (NLP) task that creates a concise and informative summary of a longer text, which can be challenging and time-consuming. Large language models (LLMs) can generate summaries of news articles, literature, technical documents, and other types of text. This lightweight web application is designed to quickly summarize any document in PDF format using an open-source LLM, making the process more efficient and less tedious.

<a href="https://github.com/shihjen/PDF_QuickSummary" class="button-link">View Project</a>

![youtube](/assets/img/pdf_summarizer.png)

## GeminiAI TalentScout

<td>
  <a href=' '><img src="https://img.shields.io/badge/Streamlit-red" alt="Streamlit Badge"></a>
  <a href=' '><img src="https://img.shields.io/badge/Large Language Model-purple" alt="Large Language Model Badge"></a> 
</td>

The ATS (Application Tracking System) web application leverages the capabilities of a large language model to streamline and enhance the recruitment process. By integrating advanced natural language processing, the application aims to improve the efficiency and accuracy of managing job applications, from initial receipt to final decision. The system is designed to automate various tasks such as parsing resumes, matching candidate qualifications with job requirements, and providing insightful summaries and recommendations.

<a href="https://github.com/shihjen/Application_Tracking_System" class="button-link">View Project</a>

![youtube](/assets/img/ats.jpg)

## Document QA ChatBot

<td>
  <a href=' '><img src="https://img.shields.io/badge/Streamlit-red" alt="Streamlit Badge"></a>
  <a href=' '><img src="https://img.shields.io/badge/Large Language Model-purple" alt="Large Language Model Badge"></a> 
</td>

A chatbot designed to answer questions directly from your uploaded documents. Utilizing state-of-the-art open source language models and embeddings, the Document QA ChatBot processes and analyzes your PDFs to provide accurate and context-specific answers. Whether you need to extract information from research papers, reports, or any other documents, Document QA ChatBot is here to help with seamless, interactive Q&A capabilities.

<a href="https://github.com/shihjen/Document_QA_ChatBot">View Project</a>

![document_chat](/assets/img/docchat.jpg)

## WikiTable Extractor

<td>
  <a href=' '><img src="https://img.shields.io/badge/Streamlit-red" alt="Streamlit Badge"></a>
</td>

The WikiTable Extractor is designed to simplify the process of extracting tables from Wikipedia pages. By entering the URL of a Wikipedia page, users can quickly and efficiently pull all the tables present on the page into a usable format. This tool leverages the extensive data resources available on Wikipedia, making it a valuable asset for anyone needing to analyze, manipulate, or repurpose structured data.

<a href="https://github.com/shihjen/WikiTable_Extractor" class="button-link">View Project</a>

![wikitable](/assets/img/htmltable.jpg)


## BCEAD Laboratory Website

<td>
  <a href=' '><img src="https://img.shields.io/badge/HTML-e34c26" alt="HTML Badge"></a>
  <a href=' '><img src="https://img.shields.io/badge/CSS-blue" alt="CSS Badge"></a> 
</td>

A comprehensive website designed to keep the public informed about the research activities in Assistant Professor Dr. Chris Sham Lok-To's laboratory. The site provides detailed information on the lab's research scope, publications, team members, and events, ensuring that the latest updates on the group's work are easily accessible.

<a href="https://bcead.github.io/chris-sham-lab/" class="button-link">Visit Website</a>

![BCEAD_Banner](/assets/img/bcead.png)




